task_config:
  seed: 1337
  info_in_reset: True
  ctrl_freq: 60
  pyb_freq: 60
  physics: dyn_si
  quad_type: 4
  normalized_rl_action_space: True

  init_state:
    init_x: 0
    init_x_dot: 0
    init_z: 1.0
    init_z_dot: 0
    init_theta: 0
    init_theta_dot: 0
  randomized_init: True
  randomized_inertial_prop: True

  init_state_randomization_info:
    init_x:
      distrib: 'uniform'
      low: -0.05
      high: 0.05
    init_x_dot:
      distrib: 'uniform'
      low: -0.05
      high: 0.05
    init_z:
      distrib: 'uniform'
      low: -0.05
      high: 0.05
    init_z_dot:
      distrib: 'uniform'
      low: -0.05
      high: 0.05
    init_theta:
      distrib: 'uniform'
      low: -0.05
      high: 0.05
    init_theta_dot:
      distrib: 'uniform'
      low: -0.05
      high: 0.05

  inertial_prop_randomization_info:
    beta_1: # Nominal: 18.11
      distrib: 'uniform'
      low: -4
      high: 4
    beta_2: # Nominal: 3.68
      distrib: 'uniform'
      low: -0.7
      high: 0.7
    alpha_1:  # Nominal: -140.8
      distrib: 'uniform'
      low: -5
      high: 10
    alpha_2: # Nominal: -13.4
      distrib: 'uniform'
      low: -3
      high: 3
    alpha_3:  # Nominal: 124.8
      distrib: 'uniform'
      low: -5
      high: 5

  task: traj_tracking
  task_info:
    trajectory_type: figure8
    num_cycles: 2
    trajectory_plane: 'xz'
    trajectory_position_offset: [0, 1.]
    trajectory_scale: 1.0

  inertial_prop:
    M: 0.033
    Iyy: 1.4e-05

  episode_len_sec: 11
  cost: rl_reward
  obs_goal_horizon: 1

  # RL Reward
  rew_state_weight: [10., .1, 10., .1, .1, 0.001]
  rew_act_weight: [.1, .1]
  rew_exponential: True

  disturbances:
    dynamics:
      - disturbance_func: white_noise
        std: 0.05
    observation:
      - disturbance_func: white_noise
        std: [5.6e-05, 1.5e-02, 2.9e-05, 8.0e-03, 1.3e-03, 3.6e-01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
    action:
      - disturbance_func: impulse
        magnitude: 0.01
        step_offset: 2
        duration: 1
        decary_rate: 1

  constraints:
    - constraint_form: default_constraint
      constrained_variable: state
      # upper_bounds: [2, 1, 2, 1, 0.2, 2.5]
      # lower_bounds: [-2, -1, 0, -1, -0.2, -2.5]
    - constraint_form: default_constraint
      constrained_variable: input
      upper_bounds: [0.58212, 0.7]
      lower_bounds: [0.09702, -0.7]
      # upper_bounds: [0.47628, 0.4]
      # lower_bounds: [0.079, -0.4]

  done_on_out_of_bound: True
  done_on_violation: False
